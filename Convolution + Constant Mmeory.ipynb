{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9d435bae-c85f-4368-8cd5-0eff0928458e",
      "metadata": {
        "id": "9d435bae-c85f-4368-8cd5-0eff0928458e"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bba3631e-5016-40f4-bd46-cc91e7509f3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bba3631e-5016-40f4-bd46-cc91e7509f3e",
        "outputId": "5660e1fb-a974-4e14-cb0f-fd0dbdf89015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: Ninja in /usr/local/lib/python3.10/dist-packages (1.11.1.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (0.3.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install wurlitzer\n",
        "!pip install Ninja\n",
        "!pip install dill\n",
        "import os,math,sys,torch,re,numpy as np\n",
        "from types import SimpleNamespace as ns\n",
        "from collections import namedtuple\n",
        "# from utils import show_img,load_cuda,cuda_begin,cdiv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iE4REmIYKc1Y",
      "metadata": {
        "id": "iE4REmIYKc1Y"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "KPYLNWP2Zftn",
      "metadata": {
        "id": "KPYLNWP2Zftn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.cpp_extension import load_inline\n",
        "\n",
        "import os,math,sys,torch,re,numpy as np\n",
        "from types import SimpleNamespace as ns\n",
        "from collections import namedtuple\n",
        "\n",
        "np.set_printoptions(precision=2, linewidth=140)\n",
        "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
        "\n",
        "def show_img(x, figsize=(4,3), **kwargs):\n",
        "    \"Display HW or CHW format image `x`\"\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.axis('off')\n",
        "    if len(x.shape)==3: x = x.permute(1,2,0)  # CHW -> HWC\n",
        "    plt.imshow(x.cpu(), **kwargs)\n",
        "\n",
        "cuda_begin = r'''\n",
        "#include <torch/extension.h>\n",
        "#include <stdio.h>\n",
        "#include <c10/cuda/CUDAException.h>\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
        "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
        "#define CUDA_ERR(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "__host__ __device__ inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a+b-1)/b;}\n",
        "'''\n",
        "\n",
        "def load_cuda(cuda_src, cpp_src, funcs, opt=True, verbose=False, name=None):\n",
        "    \"Simple wrapper for torch.utils.cpp_extension.load_inline\"\n",
        "    if name is None: name = funcs[0]\n",
        "    # flags = \"-O3 -Xptxas -O3 -Xcompiler -O3\" if opt else \"-O0 -Xptxas -O0 -Xcompiler -O0\"\n",
        "    return load_inline(cuda_sources=[cuda_src], cpp_sources=[cpp_src], functions=funcs, verbose=verbose, name=name)\n",
        "\n",
        "def cdiv(a,b):\n",
        "    \"Int ceiling division of `a` over `b`\"\n",
        "    return (a+b-1)//b\n",
        "\n",
        "def get_sig(fname, src):\n",
        "    res = re.findall(rf'^(.+\\s+{fname}\\(.*?\\))\\s*{{?\\s*$', src, re.MULTILINE)\n",
        "    return res[0]+';' if res else None\n",
        "\n",
        "dim3 = namedtuple('dim3', ['x','y','z'], defaults=(1,1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "V7wlHElmLzoV",
      "metadata": {
        "id": "V7wlHElmLzoV"
      },
      "outputs": [],
      "source": [
        "%load_ext wurlitzer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_xiJm91DL47I",
      "metadata": {
        "id": "_xiJm91DL47I"
      },
      "source": [
        "# Basic Parallel Approach\n",
        "##Python Version in CUDA format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "J7EqszwHaSLz",
      "metadata": {
        "id": "J7EqszwHaSLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f99daaa-a1ba-4845-8c2f-8b87e670a103"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "filter = torch.ones(3,3)\n",
        "filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bbda41fd-dbbf-47d4-807a-67ad565b3bc8",
      "metadata": {
        "id": "bbda41fd-dbbf-47d4-807a-67ad565b3bc8"
      },
      "outputs": [],
      "source": [
        "# Functions\n",
        "def iterate_kernel(f, blocks, threads, *args):\n",
        "    for i0 in range(blocks.y):\n",
        "        for i1 in range(blocks.x):\n",
        "            for j0 in range(threads.y):\n",
        "                for j1 in range(threads.x):\n",
        "                    f(dim3(i1,i0), dim3(j1,j0), threads, *args)\n",
        "\n",
        "def two_to_one(r,c,c_size):\n",
        "    return r + (c * c_size)\n",
        "\n",
        "def conv_kernel(blockIdx, threadIdx, blockDim, m, out, w, h):\n",
        "    r = blockIdx.y*blockDim.y + threadIdx.y\n",
        "    c = blockIdx.x*blockDim.x + threadIdx.x\n",
        "\n",
        "    index = two_to_one(r,c,h)\n",
        "\n",
        "    c_out = 0\n",
        "    iterate = []\n",
        "\n",
        "    for x in range(r-1, r+2):\n",
        "      for y in range(c-1, c+2):\n",
        "        if (x>=0 and x<w and y>=0 and y<h):\n",
        "          iterate.append([x,y])\n",
        "          c_out = c_out + m[two_to_one(x,y,h)]\n",
        "\n",
        "    out[index] = c_out\n",
        "\n",
        "\n",
        "def convolution_22(m):\n",
        "    w,h  = m.shape\n",
        "    assert w==h, \"Size mismatch!\"\n",
        "    output = torch.zeros(w,h, dtype=m.dtype)\n",
        "\n",
        "    # Thread block size (3x3)\n",
        "    thread_block = dim3(3, 3)\n",
        "\n",
        "    # Calculate the number of blocks needed\n",
        "    blocks_x = math.ceil(w / thread_block.x)\n",
        "    blocks_y = math.ceil(h / thread_block.y)\n",
        "    blocks = dim3(blocks_x, blocks_y)\n",
        "\n",
        "    # Create the output tensor\n",
        "    output = torch.zeros((w, h), dtype=m.dtype)\n",
        "\n",
        "    iterate_kernel(conv_kernel, blocks, thread_block,\n",
        "                 m.flatten(), output.flatten(), w, h)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.ones(6,6)\n",
        "input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGOxe2UpKLL7",
        "outputId": "b4d5995a-558e-4b94-8f52-7b723171f99c"
      },
      "id": "JGOxe2UpKLL7",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "VczHNC_8i5rk",
      "metadata": {
        "id": "VczHNC_8i5rk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f894c4c6-bdff-49e5-95f8-58d9df54e16a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 6., 6., 6., 6., 4.],\n",
              "        [6., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 6.],\n",
              "        [4., 6., 6., 6., 6., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "out = convolution_22(input)\n",
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numba Version"
      ],
      "metadata": {
        "id": "AXhOVK_KmWh6"
      },
      "id": "AXhOVK_KmWh6"
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "from numba.cuda import as_cuda_array as ca\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def cuda_numba(m, out):\n",
        "    cbi,cbd,tid = cuda.blockIdx,cuda.blockDim,cuda.threadIdx\n",
        "    tc,tr = tid.x,tid.y\n",
        "    r, c = cbi.y * cbd.y + tr, cbi.x * cbd.x + tc\n",
        "    h, w = m.shape[0], m.shape[1]\n",
        "    index = r*w + c\n",
        "    c_out = 0\n",
        "    for x in range(max(0, r - 1), min(r + 2, h)):\n",
        "      for y in range(max(0, c - 1), min(c + 2, w)):\n",
        "          c_out += m[x, y]\n",
        "    out[r, c] = c_out\n",
        "\n",
        "\n",
        "def conv_cuda(m):\n",
        "\n",
        "    w,h = m.shape\n",
        "    output = torch.zeros(w,h, dtype=m.dtype, device=m.device)\n",
        "    thread_block = dim3(3, 3)\n",
        "    log = np.zeros(w * h, dtype=np.int32)  # Create a log array\n",
        "\n",
        "    # Calculate the number of blocks needed\n",
        "    blocks_x = math.ceil(w / thread_block.x)\n",
        "    blocks_y = math.ceil(h / thread_block.y)\n",
        "    blocks = blocks_x, blocks_y\n",
        "\n",
        "    # Create the output tensor\n",
        "\n",
        "    cuda_numba[blocks, (3,3)](ca(m), ca(output))\n",
        "\n",
        "\n",
        "    return output\n",
        "\n",
        "conv_cuda(torch.ones(12,12).to(\"cuda\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z7lEDqImYBf",
        "outputId": "64d0c8ad-eb46-4d42-ca8f-d223f14048af"
      },
      "id": "_Z7lEDqImYBf",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 4.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [4., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 4.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA Version"
      ],
      "metadata": {
        "id": "paYJqKTNLqmu"
      },
      "id": "paYJqKTNLqmu"
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src = cuda_begin + r'''\n",
        "__constant__ float c_M[9] = {1, 1, 1, 1, 1, 1, 1, 1, 1};\n",
        "\n",
        "__device__ int two_to_one(int r, int c, int c_size) {\n",
        "    return r * c_size + c;  // Adjusted for correct row-major indexing\n",
        "}\n",
        "\n",
        "__global__ void conv_kernel(const float* m, float* out, int w, int h) {\n",
        "    int r = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int c = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (r < w && c < h) {\n",
        "        int index = two_to_one(r, c, h);\n",
        "\n",
        "        float c_out = 0.0f;\n",
        "        int maskIndex = 0;\n",
        "\n",
        "        for (int x = r - 1; x <= r + 1; x++) {\n",
        "            for (int y = c - 1; y <= c + 1; y++) {\n",
        "                if (x >= 0 && x < w && y >= 0 && y < h) {\n",
        "                    c_out += m[two_to_one(x, y, h)] * c_M[maskIndex];\n",
        "                }\n",
        "                maskIndex++;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        out[index] = c_out;\n",
        "    }\n",
        "}\n",
        "'''\n",
        "\n",
        "cuda_src += r'''\n",
        "torch::Tensor convolution_22(torch::Tensor m) {\n",
        "    int w = m.size(0);\n",
        "    int h = m.size(1);\n",
        "\n",
        "    auto options = torch::TensorOptions().dtype(m.dtype()).device(m.device());\n",
        "    torch::Tensor output = torch::zeros({w, h}, options);\n",
        "\n",
        "    dim3 thread_block(3, 3);\n",
        "    int blocks_x = std::ceil(static_cast<float>(w) / thread_block.x);\n",
        "    int blocks_y = std::ceil(static_cast<float>(h) / thread_block.y);\n",
        "    dim3 blocks(blocks_x, blocks_y);\n",
        "\n",
        "    conv_kernel<<<blocks, thread_block>>>(m.data_ptr<float>(), output.data_ptr<float>(), w, h);\n",
        "\n",
        "    // Wait for the GPU to finish and check for any errors\n",
        "    cudaDeviceSynchronize();\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "\n",
        "    return output;\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "diTTqxB4MOeP"
      },
      "id": "diTTqxB4MOeP",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname = \"convolution_22\"\n",
        "cpp_src = get_sig(fname, cuda_src)\n",
        "cpp_src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Cc5sjAgoM5ol",
        "outputId": "751f9b68-6b7a-40fc-bc07-c450894822d4"
      },
      "id": "Cc5sjAgoM5ol",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch::Tensor convolution_22(torch::Tensor m);'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZKwSCminODvA"
      },
      "id": "ZKwSCminODvA"
    },
    {
      "cell_type": "code",
      "source": [
        "module = load_cuda(cuda_src, cpp_src, [fname], opt=True)"
      ],
      "metadata": {
        "id": "HOl8pXbnM-OD"
      },
      "id": "HOl8pXbnM-OD",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2IoOujMOEIx",
        "outputId": "9de3d3ad-d4b9-4683-f9cb-e21e6dad0904"
      },
      "id": "U2IoOujMOEIx",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__spec__',\n",
              " 'convolution_22']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "py_out = convolution_22(input)\n",
        "cuda_out = module.convolution_22(input.to(\"cuda\"))"
      ],
      "metadata": {
        "id": "J8OPUutiOyCH"
      },
      "id": "J8OPUutiOyCH",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0MYA02zQeVj",
        "outputId": "42f95d42-e6aa-4daf-e0fe-f064f1791f6b"
      },
      "id": "B0MYA02zQeVj",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 6., 6., 6., 6., 4.],\n",
              "        [6., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 6.],\n",
              "        [4., 6., 6., 6., 6., 4.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memory tiling\n",
        "\n",
        "## Numba version"
      ],
      "metadata": {
        "id": "kQpeL8ACNpAx"
      },
      "id": "kQpeL8ACNpAx"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from numba import cuda\n",
        "\n",
        "# Constants\n",
        "IN_TILE_DIM = 32\n",
        "FILTER_RADIUS = 1\n",
        "OUT_TILE_DIM = IN_TILE_DIM - 2 * FILTER_RADIUS\n",
        "FILTER_DIM = 2 * FILTER_RADIUS + 1\n",
        "\n",
        "# Assuming a filter of some specific size, define the filter as a numpy array\n",
        "F_host = np.ones((FILTER_DIM, FILTER_DIM), dtype=np.float32)\n",
        "\n",
        "@cuda.jit\n",
        "def cuda_tiled(N, O, width, height):\n",
        "    col = cuda.blockIdx.x * OUT_TILE_DIM + cuda.threadIdx.x - FILTER_RADIUS\n",
        "    row = cuda.blockIdx.y * OUT_TILE_DIM + cuda.threadIdx.y - FILTER_RADIUS\n",
        "\n",
        "    # Shared memory\n",
        "    N_s = cuda.shared.array(shape=(IN_TILE_DIM, IN_TILE_DIM), dtype=np.float32)\n",
        "\n",
        "    # Load input tile into shared memory\n",
        "    if 0 <= row < height and 0 <= col < width:\n",
        "        N_s[cuda.threadIdx.y, cuda.threadIdx.x] = N[row, col]\n",
        "    else:\n",
        "        N_s[cuda.threadIdx.y, cuda.threadIdx.x] = 0.0\n",
        "\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    # Ensure the thread corresponds to a valid output element\n",
        "    if (0 <= col < width and 0 <= row < height):\n",
        "        # Initialize the sum for the current output element\n",
        "        sum = 0.0\n",
        "        # Iterate over the filter\n",
        "        for i in range(FILTER_DIM):\n",
        "            for j in range(FILTER_DIM):\n",
        "                # Calculate the global row and column indices for the current filter element\n",
        "                r = row - FILTER_RADIUS + i\n",
        "                c = col - FILTER_RADIUS + j\n",
        "                # Check if the filter element corresponds to a valid input element\n",
        "                if (0 <= r < height and 0 <= c < width):\n",
        "                    # Update the sum for the current output element\n",
        "                    sum += N_s[cuda.threadIdx.y - FILTER_RADIUS + i, cuda.threadIdx.x - FILTER_RADIUS + j] * F_host[i, j]\n",
        "        # Write the sum to the current output element\n",
        "        O[row, col] = sum\n",
        "\n",
        "\n",
        "\n",
        "# Prepare data\n",
        "N = torch.ones(9, 9).to(\"cuda\")\n",
        "O = torch.zeros(9,9).to(\"cuda\")\n",
        "\n",
        "height, width = N.shape[0], N.shape[1]\n",
        "\n",
        "\n",
        "# Define grid and block dimensions\n",
        "block_dim = (IN_TILE_DIM, IN_TILE_DIM)\n",
        "grid_dim_x = (width + OUT_TILE_DIM - 1) // OUT_TILE_DIM\n",
        "grid_dim_y = (height + OUT_TILE_DIM - 1) // OUT_TILE_DIM\n",
        "grid_dim = (grid_dim_x, grid_dim_y)\n",
        "\n",
        "\n",
        "# Transfer filter to constant memory (you may need to adjust this based on your filter)\n",
        "F_global_mem = cuda.to_device(F_host)\n",
        "\n",
        "# Launch kernel\n",
        "cuda_tiled[grid_dim, block_dim](N, O, width, height)\n",
        "\n",
        "# Copy the result back to the host if needed\n",
        "# O_host = O.copy_to_host()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHP4KqMaNAjU",
        "outputId": "cc65508b-09e5-4f72-f96d-8d02386c31ba"
      },
      "id": "BHP4KqMaNAjU",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer\n",
        "O"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAztvAmnSCth",
        "outputId": "148afdfc-8442-4120-8a19-05034e314044"
      },
      "id": "xAztvAmnSCth",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 6., 6., 6., 6., 6., 6., 6., 4.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [4., 6., 6., 6., 6., 6., 6., 6., 4.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA Version"
      ],
      "metadata": {
        "id": "393uvEeNmyGi"
      },
      "id": "393uvEeNmyGi"
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src = cuda_begin + r'''\n",
        "\n",
        "#define IN_TILE_DIM 32\n",
        "#define FILTER_RADIUS 1\n",
        "#define OUT_TILE_DIM (IN_TILE_DIM - 2 * FILTER_RADIUS)\n",
        "#define FILTER_DIM (2 * FILTER_RADIUS + 1)\n",
        "\n",
        "#define FILTER_DIM 3\n",
        "\n",
        "__constant__ float F[FILTER_DIM][FILTER_DIM] = {\n",
        "    {1.0f, 1.0f, 1.0f},\n",
        "    {1.0f, 1.0f, 1.0f},\n",
        "    {1.0f, 1.0f, 1.0f}\n",
        "};\n",
        "\n",
        "\n",
        "__global__ void cuda_tiled(const float *N, float *O, int width, int height) {\n",
        "    int col = blockIdx.x * OUT_TILE_DIM + threadIdx.x - FILTER_RADIUS;\n",
        "    int row = blockIdx.y * OUT_TILE_DIM + threadIdx.y - FILTER_RADIUS;\n",
        "\n",
        "    extern __shared__ float N_s[];\n",
        "\n",
        "    if (0 <= row && row < height && 0 <= col && col < width) {\n",
        "        N_s[threadIdx.y * IN_TILE_DIM + threadIdx.x] = N[row * width + col];\n",
        "    } else {\n",
        "        N_s[threadIdx.y * IN_TILE_DIM + threadIdx.x] = 0.0f;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (0 <= col && col < width && 0 <= row && row < height) {\n",
        "        float sum = 0.0f;\n",
        "        for (int i = 0; i < FILTER_DIM; i++) {\n",
        "            for (int j = 0; j < FILTER_DIM; j++) {\n",
        "                int r = row - FILTER_RADIUS + i;\n",
        "                int c = col - FILTER_RADIUS + j;\n",
        "                if (0 <= r && r < height && 0 <= c && c < width) {\n",
        "                    sum += N_s[(threadIdx.y - FILTER_RADIUS + i) * IN_TILE_DIM + (threadIdx.x - FILTER_RADIUS + j)] * F[i][j];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        O[row * width + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "XaM0h5fvmys7"
      },
      "id": "XaM0h5fvmys7",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src +=  r'''\n",
        "torch::Tensor convolution_tiled(torch::Tensor N) {\n",
        "    // Ensure tensor is on CUDA and is of float type\n",
        "    N = N.to(at::kCUDA).to(at::kFloat);\n",
        "\n",
        "    // Get dimensions\n",
        "    int height = N.size(0);\n",
        "    int width = N.size(1);\n",
        "\n",
        "    // Allocate output tensor\n",
        "    auto O = torch::zeros({height, width}, N.options());\n",
        "\n",
        "    // Calculate grid and block dimensions\n",
        "    dim3 block_dim(IN_TILE_DIM, IN_TILE_DIM);\n",
        "    dim3 grid_dim((width + OUT_TILE_DIM - 1) / OUT_TILE_DIM, (height + OUT_TILE_DIM - 1) / OUT_TILE_DIM);\n",
        "\n",
        "    // Shared memory size\n",
        "    int shared_mem_size = IN_TILE_DIM * IN_TILE_DIM * sizeof(float);\n",
        "\n",
        "    // Launch kernel\n",
        "    cuda_tiled<<<grid_dim, block_dim, shared_mem_size>>>(N.data_ptr<float>(), O.data_ptr<float>(), width, height);\n",
        "\n",
        "    // Wait for CUDA to finish and check for errors\n",
        "    cudaDeviceSynchronize();\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "\n",
        "    return O;\n",
        "}\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "# N = torch.ones(9, 9).to(\"cuda\")\n",
        "# O = torch.zeros(9,9).to(\"cuda\")\n",
        "\n",
        "# height, width = N.shape[0], N.shape[1]\n",
        "\n",
        "\n",
        "# # Define grid and block dimensions\n",
        "# block_dim = (IN_TILE_DIM, IN_TILE_DIM)\n",
        "# grid_dim_x = (width + OUT_TILE_DIM - 1) // OUT_TILE_DIM\n",
        "# grid_dim_y = (height + OUT_TILE_DIM - 1) // OUT_TILE_DIM\n",
        "# grid_dim = (grid_dim_x, grid_dim_y)\n",
        "\n",
        "\n",
        "# # Transfer filter to constant memory (you may need to adjust this based on your filter)\n",
        "# F_global_mem = cuda.to_device(F_host)\n",
        "\n",
        "# # Launch kernel\n",
        "# cuda_tiled[grid_dim, block_dim](N, O, width, height)\n"
      ],
      "metadata": {
        "id": "PLSpnVxBnBR6"
      },
      "id": "PLSpnVxBnBR6",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname = \"convolution_tiled\"\n"
      ],
      "metadata": {
        "id": "FsWjFUkanIHl"
      },
      "id": "FsWjFUkanIHl",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpp_src = get_sig(fname, cuda_src)\n",
        "cpp_src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YbmMIDb1nCwH",
        "outputId": "b8c115ea-6866-4c0d-b649-80f8c0c21dd2"
      },
      "id": "YbmMIDb1nCwH",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch::Tensor convolution_tiled(torch::Tensor N);'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "module = load_cuda(cuda_src, cpp_src, [fname], opt=True)"
      ],
      "metadata": {
        "id": "sYOUS7fDobbG"
      },
      "id": "sYOUS7fDobbG",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg6K0UCUokSn",
        "outputId": "7c4b0603-8ba7-4dfd-9141-c54497deed85"
      },
      "id": "Sg6K0UCUokSn",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__spec__',\n",
              " 'convolution_tiled']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = torch.ones(9, 9)\n",
        "type(N[0][0].item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw0-0rPDoet0",
        "outputId": "6f272d1e-1034-4baf-9570-220b887630ed"
      },
      "id": "bw0-0rPDoet0",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "float"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = torch.ones(9, 9).to(\"cuda\")\n",
        "out = module.convolution_tiled(N)"
      ],
      "metadata": {
        "id": "-em11xT1pNfM"
      },
      "id": "-em11xT1pNfM",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmNG2qFyuZM1",
        "outputId": "87d3a5ce-be71-4180-9c8a-9c4cc7b02aa2"
      },
      "id": "QmNG2qFyuZM1",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 6., 6., 6., 6., 6., 6., 6., 4.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [6., 9., 9., 9., 9., 9., 9., 9., 6.],\n",
              "        [4., 6., 6., 6., 6., 6., 6., 6., 4.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h4nF_BdnuZG7"
      },
      "id": "h4nF_BdnuZG7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "AXhOVK_KmWh6"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}