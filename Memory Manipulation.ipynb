{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9d435bae-c85f-4368-8cd5-0eff0928458e",
      "metadata": {
        "id": "9d435bae-c85f-4368-8cd5-0eff0928458e"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bba3631e-5016-40f4-bd46-cc91e7509f3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bba3631e-5016-40f4-bd46-cc91e7509f3e",
        "outputId": "90f3d55f-f712-416e-e343-6f7294489131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wurlitzer\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Installing collected packages: wurlitzer\n",
            "Successfully installed wurlitzer-3.0.3\n",
            "Collecting Ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Ninja\n",
            "Successfully installed Ninja-1.11.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install wurlitzer\n",
        "!pip install Ninja\n",
        "import os,math,sys,torch,re,numpy as np\n",
        "from types import SimpleNamespace as ns\n",
        "from collections import namedtuple\n",
        "# from utils import show_img,load_cuda,cuda_begin,cdiv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "iE4REmIYKc1Y"
      },
      "id": "iE4REmIYKc1Y"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.cpp_extension import load_inline\n",
        "\n",
        "import os,math,sys,torch,re,numpy as np\n",
        "from types import SimpleNamespace as ns\n",
        "from collections import namedtuple\n",
        "\n",
        "np.set_printoptions(precision=2, linewidth=140)\n",
        "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
        "\n",
        "def show_img(x, figsize=(4,3), **kwargs):\n",
        "    \"Display HW or CHW format image `x`\"\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.axis('off')\n",
        "    if len(x.shape)==3: x = x.permute(1,2,0)  # CHW -> HWC\n",
        "    plt.imshow(x.cpu(), **kwargs)\n",
        "\n",
        "cuda_begin = r'''\n",
        "#include <torch/extension.h>\n",
        "#include <stdio.h>\n",
        "#include <c10/cuda/CUDAException.h>\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
        "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
        "#define CUDA_ERR(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "__host__ __device__ inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a+b-1)/b;}\n",
        "'''\n",
        "\n",
        "def load_cuda(cuda_src, cpp_src, funcs, opt=True, verbose=False, name=None):\n",
        "    \"Simple wrapper for torch.utils.cpp_extension.load_inline\"\n",
        "    if name is None: name = funcs[0]\n",
        "    flags = \"-O3 -Xptxas -O3 -Xcompiler -O3\" if opt else \"-O0 -Xptxas -O0 -Xcompiler -O0\"\n",
        "    return load_inline(cuda_sources=[cuda_src], cpp_sources=[cpp_src], functions=funcs,\n",
        "                       extra_cuda_cflags=[flags], verbose=verbose, name=name)\n",
        "\n",
        "def cdiv(a,b):\n",
        "    \"Int ceiling division of `a` over `b`\"\n",
        "    return (a+b-1)//b\n"
      ],
      "metadata": {
        "id": "KPYLNWP2Zftn"
      },
      "id": "KPYLNWP2Zftn",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext wurlitzer"
      ],
      "metadata": {
        "id": "V7wlHElmLzoV"
      },
      "id": "V7wlHElmLzoV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python Version in CUDA format"
      ],
      "metadata": {
        "id": "_xiJm91DL47I"
      },
      "id": "_xiJm91DL47I"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "dim3 = namedtuple('dim3', ['x','y','z'], defaults=(1,1))\n",
        "d = dim3(2,3)\n",
        "m1 = torch.rand(5120, 256)\n",
        "m1s = m1[:4]\n",
        "m2 = torch.rand(256,5120)\n",
        "m2s = m2[:,:4]"
      ],
      "metadata": {
        "id": "J7EqszwHaSLz"
      },
      "id": "J7EqszwHaSLz",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "bbda41fd-dbbf-47d4-807a-67ad565b3bc8",
      "metadata": {
        "id": "bbda41fd-dbbf-47d4-807a-67ad565b3bc8"
      },
      "outputs": [],
      "source": [
        "# Functions\n",
        "def iterate_kerenel(f, blocks, threads, *args):\n",
        "    for i0 in range(blocks.y):\n",
        "        for i1 in range(blocks.x):\n",
        "            for j0 in range(threads.y):\n",
        "                for j1 in range(threads.x): f(dim3(i1,i0), dim3(j1,j0), threads, *args)\n",
        "\n",
        "def matmul_kernel(blockIdx, threadIdx, blockDim, m, n, out, h, w, k):\n",
        "    r = blockIdx.y*blockDim.y + threadIdx.y\n",
        "    c = blockIdx.x*blockDim.x + threadIdx.x\n",
        "\n",
        "    # boundary checking\n",
        "    if (r>=h or c>=w):\n",
        "       return\n",
        "\n",
        "    # matrix multiplication loop over flattened tensors\n",
        "    o = 0.0\n",
        "    for i in range(k):\n",
        "      o += m[r*k+i] * n[i*w+c]\n",
        "    out[r*w+c] = o\n",
        "\n",
        "\n",
        "\n",
        "def matmul(m, n):\n",
        "    h,k  = m.shape\n",
        "    k2,w = n.shape\n",
        "    assert k==k2, \"Size mismatch!\"\n",
        "    output = torch.zeros(h, w, dtype=m.dtype)\n",
        "    tpb = dim3(16,16)\n",
        "    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n",
        "    iterate_kerenel(matmul_kernel, blocks, tpb,\n",
        "                 m.flatten(), n.flatten(), output.flatten(), h, w, k)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5b57350f-3ff6-4e10-8635-040c3736220d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b57350f-3ff6-4e10-8635-040c3736220d",
        "outputId": "19d003f0-d338-45b8-c630-da891c127853"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Test\n",
        "torch.isclose(matmul(m1s, m2s), m1s@m2s).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA version"
      ],
      "metadata": {
        "id": "yiZ-53_CMdz7"
      },
      "id": "yiZ-53_CMdz7"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fbSzJz_lMu6V"
      },
      "id": "fbSzJz_lMu6V",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}