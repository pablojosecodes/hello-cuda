{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ELLpack storage format for sparse matrices: Store (both in column major order)\n",
        "- Matrix: nonzeros grouped by rows + padding\n",
        "- Matrix: indices of each (equal padding as above)\n",
        "\n",
        "Thus, the approach to SpMV is as follow:\n",
        "- Assin a thread â†’ each input row\n",
        "- Loops over input row\n",
        "- Updates output"
      ],
      "metadata": {
        "id": "bOO6N1wEphsv"
      },
      "id": "bOO6N1wEphsv"
    },
    {
      "cell_type": "markdown",
      "id": "9d435bae-c85f-4368-8cd5-0eff0928458e",
      "metadata": {
        "id": "9d435bae-c85f-4368-8cd5-0eff0928458e"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bba3631e-5016-40f4-bd46-cc91e7509f3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bba3631e-5016-40f4-bd46-cc91e7509f3e",
        "outputId": "1ee4cd1b-e6fa-4738-bc30-3743328f0a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: Ninja in /usr/local/lib/python3.10/dist-packages (1.11.1.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (0.3.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install wurlitzer\n",
        "!pip install Ninja\n",
        "!pip install dill\n",
        "import os,math,sys,torch,re,numpy as np\n",
        "from types import SimpleNamespace as ns\n",
        "from collections import namedtuple\n",
        "# from utils import show_img,load_cuda,cuda_begin,cdiv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iE4REmIYKc1Y",
      "metadata": {
        "id": "iE4REmIYKc1Y"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KPYLNWP2Zftn",
      "metadata": {
        "id": "KPYLNWP2Zftn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.cpp_extension import load_inline\n",
        "\n",
        "import os,math,sys,torch,re,numpy as np\n",
        "from types import SimpleNamespace as ns\n",
        "from collections import namedtuple\n",
        "\n",
        "np.set_printoptions(precision=2, linewidth=140)\n",
        "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
        "\n",
        "def show_img(x, figsize=(4,3), **kwargs):\n",
        "    \"Display HW or CHW format image `x`\"\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.axis('off')\n",
        "    if len(x.shape)==3: x = x.permute(1,2,0)  # CHW -> HWC\n",
        "    plt.imshow(x.cpu(), **kwargs)\n",
        "\n",
        "cuda_begin = r'''\n",
        "#include <torch/extension.h>\n",
        "#include <stdio.h>\n",
        "#include <c10/cuda/CUDAException.h>\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
        "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
        "#define CUDA_ERR(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "__host__ __device__ inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a+b-1)/b;}\n",
        "'''\n",
        "\n",
        "def load_cuda(cuda_src, cpp_src, funcs, opt=True, verbose=False, name=None):\n",
        "    \"Simple wrapper for torch.utils.cpp_extension.load_inline\"\n",
        "    if name is None: name = funcs[0]\n",
        "    # flags = \"-O3 -Xptxas -O3 -Xcompiler -O3\" if opt else \"-O0 -Xptxas -O0 -Xcompiler -O0\"\n",
        "    return load_inline(cuda_sources=[cuda_src], cpp_sources=[cpp_src], functions=funcs, verbose=verbose, name=name)\n",
        "\n",
        "def cdiv(a,b):\n",
        "    \"Int ceiling division of `a` over `b`\"\n",
        "    return (a+b-1)//b\n",
        "\n",
        "def get_sig(fname, src):\n",
        "    res = re.findall(rf'^(.+\\s+{fname}\\(.*?\\))\\s*{{?\\s*$', src, re.MULTILINE)\n",
        "    return res[0]+';' if res else None\n",
        "\n",
        "dim3 = namedtuple('dim3', ['x','y','z'], defaults=(1,1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V7wlHElmLzoV",
      "metadata": {
        "id": "V7wlHElmLzoV"
      },
      "outputs": [],
      "source": [
        "%load_ext wurlitzer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_xiJm91DL47I",
      "metadata": {
        "id": "_xiJm91DL47I"
      },
      "source": [
        "# Numba Version in CUDA format\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "\n",
        "@cuda.jit\n",
        "def kogge_kernel(nonzeros, indices, v, product):\n",
        "    \"\"\"\n",
        "    Kernel for computing sparse matrix-vector multiplication (SpMV)\n",
        "    using the ELLPACK format.\n",
        "\n",
        "    Parameters:\n",
        "    - nonzeros: 2D array with nonzero values of the matrix, column-major.\n",
        "    - indices: Corresponding column indices for nonzeros, same shape as nonzeros.\n",
        "    - v: Dense vector for multiplication.\n",
        "    - product: Result vector.\n",
        "    \"\"\"\n",
        "    row = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "    if row < product.size:  # Check if within bounds\n",
        "        sum = 0.0\n",
        "        for i in range(nonzeros.shape[1]):  # Iterate over elements in row\n",
        "            col = indices[row, i]\n",
        "            if col < v.size:  # Valid column index guard\n",
        "                sum += nonzeros[row, i] * v[col]\n",
        "        product[row] = sum\n",
        "\n",
        "def run_spmv(nonzeros, indices, v, block_size=256):\n",
        "    \"\"\"\n",
        "    Function to perform SpMV using CUDA.\n",
        "\n",
        "    Parameters:\n",
        "    - nonzeros: 2D numpy array with nonzero values of the matrix, column-major.\n",
        "    - indices: Corresponding column indices for nonzeros, same shape as nonzeros.\n",
        "    - v: Dense vector for multiplication (as a numpy array).\n",
        "    - block_size: Number of threads per block.\n",
        "    \"\"\"\n",
        "    # Ensure inputs are suitable numpy arrays\n",
        "    nonzeros = np.ascontiguousarray(nonzeros)\n",
        "    indices = np.ascontiguousarray(indices)\n",
        "    v = np.ascontiguousarray(v)\n",
        "\n",
        "    num_rows = nonzeros.shape[0]\n",
        "\n",
        "    product = np.zeros(num_rows, dtype=v.dtype)\n",
        "\n",
        "    # Calculate grid dimensions\n",
        "    block_no = math.ceil(num_rows / block_size)\n",
        "\n",
        "    # Setting up device arrays\n",
        "    d_nonzeros = cuda.to_device(nonzeros)\n",
        "    d_indices = cuda.to_device(indices)\n",
        "    d_v = cuda.to_device(v)\n",
        "    d_product = cuda.to_device(product)\n",
        "\n",
        "    # Launch kernel\n",
        "    kogge_kernel[block_no, block_size](d_nonzeros, d_indices, d_v, d_product)\n",
        "\n",
        "    # Copy result back to host\n",
        "    product = d_product.copy_to_host()\n",
        "\n",
        "    return product\n",
        "\n",
        "\n",
        "nonzeros = torch.tensor([[5, 0], [8, 0], [3, 6]])\n",
        "indices = torch.tensor([[0, 0], [1, 0], [2, 2]])\n",
        "\n",
        "v = torch.tensor([1, 2, 3])\n",
        "\n",
        "result = run_spmv(nonzeros, indices, v)\n",
        "print(result)  # Output of the SpMV\n"
      ],
      "metadata": {
        "id": "yQ8sgqpAUwip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "723769c4-c0bf-490b-b2f0-99c6bd8c69c8"
      },
      "id": "yQ8sgqpAUwip",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 5 16 27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def get_sparse_unformatted_matrix(rows=10, cols=10):\n",
        "    dense_matrix = torch.zeros((rows, cols))\n",
        "\n",
        "    # Assume we want ~20% of the matrix to be non-zero\n",
        "    num_nonzeros = int(0.2 * rows * cols)\n",
        "\n",
        "    # Randomly choose indices for non-zero elements\n",
        "    # Ensure unique positions if randomness allows duplicates that you don't want\n",
        "    row_indices = torch.randint(0, rows, (num_nonzeros,))\n",
        "    col_indices = torch.randint(0, cols, (num_nonzeros,))\n",
        "\n",
        "    # Populate the selected positions with random non-zero values\n",
        "    for i in range(num_nonzeros):\n",
        "        # You can adjust the range of random values as needed\n",
        "        dense_matrix[row_indices[i], col_indices[i]] = torch.rand(1)\n",
        "    return dense_matrix\n",
        "def to_column_major(tensor):\n",
        "    \"\"\"\n",
        "    Convert a 2D tensor to column-major order by returning a transposed,\n",
        "    contiguous version of the tensor.\n",
        "\n",
        "    Note: This doesn't change the physical layout in memory to column-major\n",
        "    but returns a view that simulates the behavior.\n",
        "\n",
        "    Parameters:\n",
        "    tensor (torch.Tensor): A 2D tensor.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: A tensor transposed and made contiguous to simulate column-major order.\n",
        "    \"\"\"\n",
        "    # Transpose to change row-major to column-major indexing\n",
        "    transposed = tensor.t()\n",
        "    # Ensure the transposed tensor is contiguous\n",
        "    column_major_tensor = transposed.contiguous()\n",
        "    return column_major_tensor\n",
        "\n",
        "\n",
        "def dense_to_ell_format(dense_tensor):\n",
        "    \"\"\"\n",
        "    Convert a dense matrix (torch.Tensor) into ELL format.\n",
        "\n",
        "    Parameters:\n",
        "    dense_tensor (torch.Tensor): The dense matrix.\n",
        "\n",
        "    Returns:\n",
        "    (values, indices): A tuple of two 2D tensors - values and indices in ELL format.\n",
        "    \"\"\"\n",
        "    if not torch.is_tensor(dense_tensor) or dense_tensor.is_sparse:\n",
        "        raise ValueError(\"Input tensor must be a dense torch.Tensor\")\n",
        "\n",
        "    # Convert the dense tensor to sparse COO tensor\n",
        "    sparse_coo_tensor = dense_tensor.to_sparse()\n",
        "\n",
        "    # Ensure the input tensor is in COO format and coalesced\n",
        "    sparse_coo_tensor = sparse_coo_tensor.coalesce()\n",
        "\n",
        "    # Get the indices and values of the non-zero elements\n",
        "    indices = sparse_coo_tensor.indices()\n",
        "    values = sparse_coo_tensor.values()\n",
        "\n",
        "    num_rows, num_cols = dense_tensor.shape\n",
        "\n",
        "    # Count non-zeros in each row\n",
        "    row_nnz = torch.zeros(num_rows, dtype=torch.int64)\n",
        "    row_indices = indices[0]\n",
        "    for row_index in row_indices:\n",
        "        row_nnz[row_index] += 1\n",
        "\n",
        "    # Find the maximum number of non-zero elements in any row\n",
        "    max_nnz_per_row = torch.max(row_nnz)\n",
        "\n",
        "    # Initialize tensors for ELL format (using padding where necessary)\n",
        "    ell_values = torch.zeros((num_rows, max_nnz_per_row), dtype=values.dtype)\n",
        "    ell_indices = torch.full((num_rows, max_nnz_per_row), num_cols, dtype=torch.int64)  # Use `num_cols` as padding value\n",
        "\n",
        "    # Populate the ELL format tensors\n",
        "    current_count = torch.zeros(num_rows, dtype=torch.int64)\n",
        "    for row, col in indices.t():\n",
        "        idx = current_count[row]\n",
        "        ell_indices[row, idx] = col\n",
        "        ell_values[row, idx] = values[current_count[row]]\n",
        "        current_count[row] += 1\n",
        "\n",
        "    return to_column_major(ell_values), to_column_major(ell_indices)\n",
        "\n",
        "\n",
        "sparse = get_sparse_unformatted_matrix()\n",
        "sparse_matrix  =dense_to_ell_format(sparse)"
      ],
      "metadata": {
        "id": "aqSU_q-IqPIB"
      },
      "id": "aqSU_q-IqPIB",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(sparse_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEp-swMssW2V",
        "outputId": "f94701ed-e0f0-4b96-e960-36700a5332f5"
      },
      "id": "SEp-swMssW2V",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_matrix[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpXmbsENsjxl",
        "outputId": "0e70176d-6926-410d-fc00-2abde4aa3d88"
      },
      "id": "vpXmbsENsjxl",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_matrix[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCOlbM2DslJN",
        "outputId": "6440669f-45df-46f6-c86c-2e1a0b006b28"
      },
      "id": "wCOlbM2DslJN",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3,  2,  5,  7,  4,  3,  2,  3,  2, 10],\n",
              "        [ 5, 10, 10,  9,  5,  5,  3,  5, 10, 10],\n",
              "        [ 6, 10, 10, 10, 10,  6, 10,  7, 10, 10],\n",
              "        [ 7, 10, 10, 10, 10, 10, 10, 10, 10, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = torch.rand([10])"
      ],
      "metadata": {
        "id": "F_z8h1FmqPMc"
      },
      "id": "F_z8h1FmqPMc",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DrJfzjgTrEBC"
      },
      "id": "DrJfzjgTrEBC",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse @ vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj-GZYCiun9O",
        "outputId": "41b77cb7-939c-47bb-c567-0db68897c812"
      },
      "id": "Zj-GZYCiun9O",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0549, 0.0187, 0.3387, 0.8842, 0.8266, 0.8998, 0.1620, 1.5696, 0.0932,\n",
              "        0.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ATLLrrontjaS"
      },
      "id": "ATLLrrontjaS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}